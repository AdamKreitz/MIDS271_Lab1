---
title: "W271 Group Lab 1"
subtitle: "Investigating the 1986 Space Shuttle Challenger Accident"
author: "Adam Kreitzman, Hailee Schuele, Lee Perkins, Paul Cooper"
output: bookdown::pdf_document2
fontsize: 11pt
geometry: margin=1in
---

```{r, include=F}
library(tidyverse)
library(patchwork)
library(lmtest)
library(ggplot2)
library(car)
library(dplyr)

library(nnet)
library(GGally)
library(gridExtra)

set.seed(123)
```

\newpage

```{=tex}
\begin{abstract}
In this report we reconstruct the Dalal et al analysis surrounding the conditions of the 1989 Challenger rocket launch. We use multinomial logistic regression to predict O-ring failure, the reported cause of the launch catastrophe. We learn that temperature has a statistically and practically significant effect on O-ring failure. Like Dalal, we conclude that postponing the Challenger launch to a warmer temperature would have increased the probability of a success.
\end{abstract}
```
# Introduction

In 1986, the Challenger Space Shuttle catastrophically exploded during launch. Subsequently, the United States conducted an analysis of the incident, and the Rogers Commission published a report that concluded that the explosion was caused by faulty O-rings in the rocket motor engine assembly. Additional analysis, performed by Dalal et al, concluded that NASA had enough information from prior rocket launches to know that O-ring failure was likely on a day as cold as the Challenger launch.

## Research question

We are conducting a risk analysis based on data from 23 separate shuttle launches prior to the Challenger. In particular we are investigating whether or not Temperature and Pressure have an appreciable impact on O-ring failures. Our response variable is the number of thermally distressed primary O-rings, which can range from 0 to 6 (since there are six primary O-rings per shuttle). We will be using a binomial distribution to model the number of distressed O-rings, where the number of successes (distressed O-rings) follows a binomial distribution with a fixed number of trials (6) and a probability of success (p).

Our two potential explanatory variables are Temperature, which is measured in degrees Fahrenheit, and Pressure, whose unit of measurement is pounds per square inch (psi).

We hope to determine if there is a significant correlation between one or both of these variables to be able to make safety recommendations for limiting catastrophic O-ring failure in shuttle launches.

# Data

```{r, include=F}
# df <- read.csv("../data/raw/challenger.csv")
challenger <- read.csv("/home/rstudio/workspace/mnt/271/labs/MIDS271_Lab1/Lab_1/data/raw/challenger.csv")
```

## Explaining the Variables

**Temperature**

The temperature variable is the temperature at the moment when the O-rings were examined for failure. The temperature ranges from 53 to 81 degrees Fahrenheit in the dataset.

**Pressure**

Pressure is a categorical variable, indicating the leak test pressure, in psi, of the O-rings for a given flight. This increased over time, as pressure thresholds increased over the history of NASA launches.

**O.Rings**

O-rings are an important structural component of rocket launches that seal the field joints of the solid rocket boosters during the launch into orbit. The O-rings data from the 23 past launches is the count of how many O-rings experienced thermal distress on that flight. The data ranges between 0 and 2 failures per launch, with a theoretically possible maximum value of 6.

**Independence**

Independence is a necessary assumption of a binomial model, as a lack of independence could imply that the probability of O-ring failure is not consistent for each trial. This may be difficult to justify in this context. Each launch contains 6 field joints, and the failure of a joint may reasonably be expected to contribute to the failure of other joints on that same launch. Dalal et al were able to alleviate this concern by running a subsequent analysis, where they measured whether at least 1 O-ring failed on a given launch, which provided similar results and justified the assumption of independence.


## Description

The Challenger dataset consists of 23 observations from shuttle flights conducted prior to the Challenger launch. Observations of O-ring failures were gathered by collecting the rocket motors from the ocean after the launch. Temperature was recorded on the day of the launch, and pressure was measured as the leak test pressure of the O-rings during their assembly. Our population of interest is O-rings at any reasonable pressure and temperature from the 4-part rocket motor assembly used by NASA during the Challenger launch.

The variables of interest are described in the previous section. None of these variables have missing values and there are no outliers. While all are of numeric type, it's worth noting Temperature is continuous, Pressure is only recorded as 3 values (50, 100, 200), and O.rings only has 3 values (0, 1, 2). All observations were retained for the analysis.

## Key Features

Our EDA was mainly concentrated on looking at how the two explanatory variables (Temperature and Pressure) interacted with the response variable (O.Rings).

The first chart that we created was a scatterplot of Temperature vs. O.Rings, seen below. For the most part, O-ring failures happen at lower temperatures. There's one instance of an O-ring failure at 70 degrees and 2 O-ring failures at 75 degrees. Otherwise, we see every instance below 65 degrees resulting in at least 1 O-ring failure.

```{r scatter plots of Temp vs O.ring and Pressure vs O.ring, echo=F, fig.align="center", fig.height=2, warning=F, results='hide'}
scatter_temp <- challenger %>% ggplot(aes(y = factor(O.ring), x = Temp)) +
    geom_point() +
    ylab("O.ring") +
    labs(title = "O-ring Failures by Temperature")

scatter_pressure <- challenger %>% ggplot(aes(y = factor(O.ring), x = Pressure)) +
    geom_point() +
    ylab("O.ring") +
    labs(title = "O-ring Failures by Pressure")

scatter_temp | scatter_pressure
```

The for the graph on the right we created was a scatterplot of Pressure vs. O.Ring. This scatterplot does not make pressure seem to be a relevant factor, as we see both low pressure and high pressure have instances of O-ring failure, though it is not definitive because there are many points of overlap. It's interesting to see that at a Pressure of 100, there are no instances of O-ring failure, so there is the possibility that only extremes on either side could influence failure, but more inspection is needed.

This next scatter plot combines all three variables of interest. Again, we can see more O-ring failures clustered at lower temperatures. Failures seem to be more common at higher pressures as well, although this could be a trick of the eye as there are many more data points at higher pressure than lower pressure. Note some space is added to show points that overlap. 

```{r, echo=F, fig.align="center", fig.height=2}
challenger %>% ggplot(aes(x = Temp, y = Pressure)) +
  geom_point(aes(color = factor(O.ring)),
             position = position_jitter(width = 0.2, height = 0.2)) +
  xlab("Temperature (Fahrenheit)") +
  ylab("Pressure (psi)") +
  labs(title = "O-Ring Failures by Temperature and Pressure",
       color = "O-Ring Failures")
```

In order to more closely visualize the difference in Temperature by class, we created comparative boxplots that were sorted into the number of O-ring failures for Temperature, which is below:

```{r boxplot of Temp, echo=F, fig.align="center", fig.height=3}
boxplot(challenger$Temp ~ challenger$O.ring, xlab = "Temperature", ylab = "O.ring",
        main = "Box plot of Temperature by O.ring", horizontal = TRUE)
```

We can see a very clear upward shift in Temperature for both IQR and Median for the observations without O-ring failures versus the observations with either 1 or 2 failures.

Finally, we wanted to know about the distribution of our data for both Temperature and Pressure so that we know which ranges of variables will have the most robust analysis, so we generated the two histograms below:

```{r histograms of temp and pressure, echo=F, fig.align="center", fig.height=3, warning=F}
temp_hist <- challenger %>% ggplot(aes(x = Temp)) +
    geom_histogram(binwidth = 3) +
    xlab("Temperature") +
    labs(title = "Histogram of Temperature")
pressure_hist <- challenger %>% ggplot(aes(x = Pressure)) +
    geom_histogram(binwidth = 3) +
    xlab("Pressure") +
    labs(title = "Histogram of Temperature")

temp_hist | pressure_hist
```

For Temperature, we see that the vast majority of our observations lie between 65 degrees and 80 degrees. Our Pressure histogram is a bit funky as the data is only measured at 3 levels, but we can see the majority of measurements are at 200 PSI, with the second most being at 50 PSI, and the fewest at 100 PSI. We would expect, based on this, our analysis to be the most robust between 65 and 80 degrees and at 200 PSI.

# Analysis

## Reproducing Previous Analysis

### Logistic Regression Model
The model below imitates the logistic regression model from Dalal et al. Both explanatory variables are included as linear terms. The outcome variable specifies the count of success (O.ring) and the count of failures (6 - O.ring) to fit the binomial response requirements. The 6 here represents the total number of trials per launch, i.e. the 6 O-rings in each shuttle. 

It's worth taking a moment to acknowledge the flipped logic - The “successes” for the binomial model are defined as the number of O-ring failures. Conversely, the model “failures” are the number of O-rings that did not fail.


```{r model}
# Logistic regression from the paper
mod_full <- glm(cbind(O.ring, 6 - O.ring) ~ Temp + Pressure,
                data = challenger, family = binomial(link = "logit"))
summary(mod_full)
```

The summary results here show a coefficient of -0.098 for temperature and 0.008 for pressure. The negative relationship between temperature and O-ring suggests that for each 10 degree increase in temperature, the estimated log odds of success (i.e. O-ring failure) decrease by ~1 (-0.098 * 10), all other variables are held constant. In other words, the estimated odds of O-ring failure change by 2.67 times for a 10 degree decrease in temperature. On the other hand, for each 10 psi increase in pressure, the estimated log odds of O-ring failure increases by 0.08. This translates to a 1.08 change in odds for a 10 psi increase in pressure.

The effect size for temperature is practically significant, while the effect of pressure is less so. That said, only the coefficient for temperature is significant. 

### Likelihood Ratio Tests
To further explore the importances of our explanatory variables, we conducted a likelihood ratio test. The likelihood ratio test uses a Type II (i.e. partial) test, which, for each variable, compares a model with the variable to a model without the variable. The results below affirm our prior conclusion: only temperature is significant to the model.

```{r likelihood ratio tests}
Anova(mod_full, test = "LR")
```

### Pressure Debate
P-values from both the model summary and the likelihood ratio test suggest that pressure is not an important variable to the model. In general, it's advised to use the most parsimonious model. However, given the small sample size and that there are only two explanatory variables in the data, we argue that pressure does have some value. At the very least, one could argue there isn't enough data to support dropping pressure without a second thought. By opting to keep pressure, the effect of temperature is lessened (the temperature coefficient shrinks from -0.116 to -0.098). This means that any conclusions drawn from a temperature-only model are likely more dramatic than those drawn from a temperature + pressure model.

## Confidence Intervals

### Estimating Temperature Only Models
The models below use temperature as the only explanatory variable. The first (mod_temp) uses linear temperature. The second (mod_temp_quad) uses linear and quadratic temperature. The final anova() test compares the two temperature models to determine the importance of quadratic temperature.

```{r confidence intervals}
# Estimate model with only temperature
mod_temp <- glm(cbind(O.ring, 6 - O.ring) ~ Temp,
                data = challenger, family = binomial(link = "logit"))

# Estimate model with temperature and quadratic term
mod_temp_quad <- glm(cbind(O.ring, 6 - O.ring) ~ Temp + I(Temp^2),
                    data = challenger, family = binomial(link = "logit"))

# Determine if quadratic term is important to the model
anova(mod_temp, mod_temp_quad, test = "Chisq")
```

The high p-value in the results of the `anova()` test suggest that the quadratic term is not important to the model. In other words, there is a more linear relationship between temperature and O-ring failure.

### Plots
The first graph below shows the probability of O-ring failure across a range of temperatures. The blue bands represent the 95% Wald confidence interval. It's evident that the predicted probability of failure decreases significantly as temperature goes up. The confidence bands are also much wider at lower temperatures. This could be because there are less observations in the data at lower temperatures. The lowest recorded temperature is actually only 53 degrees, so everything below that is a generalization of the model from the rest of the data.

```{r confidence interval plot1, echo=F, fig.align="center", fig.height=3, warning=F}
# Return the coefficients of the model
beta_hat <- mod_temp$coefficients

# Define the Temperature sequence
temp_seq <- seq(from = 31, to = 81, by = 0.1)

# Get the standard error
new_data <- data.frame(Temp = temp_seq)
pred_temp <- predict(mod_temp, newdata = new_data, type = "link", se.fit = TRUE)
temp_se <- pred_temp$se.fit

pred_prob_graph <- ggplot() +
    geom_ribbon(aes(x = temp_seq,
                ymin = plogis(beta_hat[1] + beta_hat[2] * temp_seq - 1.96 * temp_se),
                ymax = plogis(beta_hat[1] + beta_hat[2] * temp_seq + 1.96 * temp_se)),
            color = "blue",
            linetype = "dotted",
            fill = NA) +
    geom_line(aes(
        x = temp_seq,
        y = 1 / (1 + exp(-(beta_hat[1] + beta_hat[2] * temp_seq)))),
        xlim = c(31, 81)
    ) +
    ylab("Predicted Probability of O-Ring Failure") +
    xlab("Temperature (Fahrenheit)") +
    labs(title = "Decreasing Probability of O-Ring Failure with Increased Temperature") + 
    scale_x_continuous(breaks = seq(30, 80, by = 10), limits = c(31, 81)) +
    scale_y_continuous(breaks = seq(0, 1, by = 0.2))

pred_probs_temp <- predict(mod_temp, newdata = new_data, type = "response")

pred_num_graph <- ggplot() +
    geom_line(
    aes(x = temp_seq, y = (pred_probs_temp * 6)),
    xlim = c(31, 81)) +
    ylab("Predicted Number of O-Ring Failures") +
    xlab("Temperature (Fahrenheit)") +
    labs(title = "Decreasing Number of O-Ring Failures with Increased Temperature") + 
    scale_x_continuous(breaks = seq(30, 80, by = 10), limits = c(31, 81)) +
    scale_y_continuous(breaks = seq(0, 6, by = 1), limits = c(0, 6))

pred_prob_graph | pred_num_graph
```

The graph on the right shows the expected number of O-ring failures across temperatures. Again we see the downward trend as temperature increases. It's worth noting that almost 5 O-ring failures are expected at 31 degrees. We'll take a closer look in the next section.

### Probability of Failure
The predicted probability of an O-ring failure at 31 degrees, the temperature during the 1986 Challenger launch, is 0.818. Because of the small number of observations in the data, we opted to use the 95% profile likelihood confidence interval instead of Wald. This resulted in a confidence interval of (0.142, 0.99). This is a very wide range of confidence, which coincides with the “Decreasing Probability of O-Ring Failure with Increased Temperature” graph.

### Model Assumptions
1. Two possible outcomes: Each O-ring either fails or doesn't, so this assumption is met.
2. Constant probability of failure: The probability of failure is constructed to depend on temperature; we have reason to believe that this probability function is constant across trials.
3. Independent & identical trials - As discussed above, independence is tricky to establish when O-rings on the same launch may be expected to have some impact on each other. By running a separate analysis on the probability of at least one failure – a scenario that avoids the same-flight dependencies – and getting similar results, we can see that this assumption isn't detrimental to our results.


## Bootstrap Confidence Intervals

For bootstrapping, we elected to do 1,000 samples, as we felt that was significantly large enough to garner the result we were looking for. Also, to keep things consistent, we made sure to sample with replacement to get accurate results. The plot for the confidence interval is below:

```{r bootstrap confidence interval plot, echo=F, fig.align="center", fig.height=3, warning=F}
# Set the number of bootstrap samples
B <- 1000

# Initialize a matrix to store the bootstrap predictions
temps <- 10:100
bootstrap_preds <- matrix(NA, nrow = B, ncol = length(temps))
colnames(bootstrap_preds) <- temps

# Run the bootstrap
for (b in 1:B) {
  # Resample the data
  bootstrap_data <- challenger[sample(nrow(challenger), replace = TRUE), ]
  # Fit the model to the bootstrap data
  bootstrap_model <- glm(cbind(O.ring, 6 - O.ring) ~ Temp, 
                         data = bootstrap_data, family = binomial)
  # Compute predictions at each temperature
  for (temp in temps) {
    bootstrap_preds[b, as.character(temp)] <- 
      predict(bootstrap_model, newdata = data.frame(Temp = temp), type = "response")
  }
}

# Compute 90% confidence intervals
ci_lower <- apply(bootstrap_preds, 2, function(x) quantile(x, 0.05))
ci_upper <- apply(bootstrap_preds, 2, function(x) quantile(x, 0.95))

# Compute mean predictions at each temperature
mean_preds <- apply(bootstrap_preds, 2, mean)
# Combine results into a data frame

results <- data.frame(
  Temperature = temps,
  Lower_CI = ci_lower,
  Upper_CI = ci_upper,
  Mean_Pred = mean_preds  # add this line
)

ggplot(results, aes(x = Temperature)) +
  geom_ribbon(aes(ymin = Lower_CI, ymax = Upper_CI), fill = "grey80") +
  geom_line(aes(y = Mean_Pred), color = "red") +  # use mean prediction here
  labs(y = "Predicted Probability of O-ring Failure",
       title = "Predicted Probabilities with 90% Confidence Intervals") +
  theme_minimal()
```

As we can see, bootstrapping made the low-temperature predictions more conservative (note that the dimensions of this graph go from 10-100, so it's a bit different from above.. Additionally, we see that the confidence interval is a bit narrower, though that can also be attributed to the fact that we used a 90% confidence interval rather than 95%. At the same time, the sampling with replacement does not really help us much at lower temperatures, as this is still missing from our model, which is why we see a very large interval below 50 degrees.

Our bootstrap method was effectively to sample our dataset with replacement 23 times with 1,000 iterations. This gave us 1,000 datasets of identical n=23, generated by sampling our original dataset with replacement. We then generated a model of each bootstrapped dataset and made predictions ranging from temp = (10, 100). Then, we generated intervals based on the predictions for each dataset.

For our specific variable of interest, we decided to look at 70 degrees, as it was a common value in our dataset and we believed it was an interesting one to look at since it is a likely temperature to see in the real world. 

Based on the results, we obtain a predicted value and 90% confidence interval of:

Predicted value: 0.045365556

90% Confidence interval: (.01201458, 0.08518981)

Interpreting these results tells us that our predicted probability of an individual O-ring failure at 70 degrees is roughly .045 (or 4.5%), and we can be 90% confidence that the true probability of an individual O-ring failure at 70 degrees is between roughly .012 (or 1.2%) and roughly .085 (or 8.5%).

## Alternative Specification

We generated a linear model based on Temperature and then proceeded to run tests to check the linearity of the data. The results were clear from examining the pattern of residuals to see if they were randomly distributed. To do so, we generated a QQ plot (below) in order to check for homoscedasticity. 

```{r qq plot, echo=F, fig.align="center", fig.height=3}
# Define a linear model
linear_model <- lm(cbind(O.ring, 6 - O.ring) ~ Temp, data = challenger)

qqnorm(resid(linear_model))
qqline(resid(linear_model))
```

We can see that the residuals are not randomly distributed in the QQ plot. This tells us that a linear model is likely not a good fit for the data. We see that at a lower quantile, the residuals tend to be highly positive, but at higher quantiles the residuals tend to be highly negative. In the middle of the data, it tends to oscillate positive and negative with smaller absolute residuals. Having these kinds of patterns in the QQ plot of linear residuals is not what you will see in a dataset that should be modeled linearly.

# Conclusions

The logistic model including both temperature and pressure,`mod_full`, is the preferred model to help make safety recommendations for limiting catastrophic O-ring failures in shuttle launches. What makes `mod_full` the preferred model is the negative relationship between the temperature and O-rings. This suggests that for each 10 degree decrease in temperature, the estimated odds of O-ring failure changes by `r round(exp(-10 * coef(mod_full)[2]) ,2)`, all other variables held constant. If we test the probability of failure for the Challenger's conditions with a Temperature of 31 and a pressure of 200, there was a `r round(predict(mod_full, newdata=data.frame(Temp=31,Pressure=200), type="response"), 4) * 100`% chance of failure. Since the dataset was small, the resulting confidence interval has a wide range making it difficult to accurately predict the chance failure. However, we did learn that temperature has a statistically significant effect on the O-ring's chance of failure. This leads us to believe that if the Challenger launched when the temperature was warmer, it would have had a lower chance of failure.

\newpage

# Lab 1, Short Questions

# Strategic Placement of Products in Grocery Stores (5 points)

These questions are taken from Question 12 of chapter 3 of the textbook(Bilder and Loughin's “Analysis of Categorical Data with R).

> *In order to maximize sales, items within grocery stores are strategically placed to draw customer attention. This exercise examines one type of item—breakfast cereal. Typically, in large grocery stores, boxes of cereal are placed on sets of shelves located on one side of the aisle. By placing particular boxes of cereals on specific shelves, grocery stores may better attract customers to them. To investigate this further, a random sample of size 10 was taken from each of four shelves at a Dillons grocery store in Manhattan, KS. These data are given in the *cereal_dillons.csv *file. The response variable is the shelf number, which is numbered from bottom (1) to top (4), and the explanatory variables are the sugar, fat, and sodium content of the cereals.*

```{r read cereal data, message=FALSE, include=F}
# setwd("/home/rstudio/workspace/mnt/271/labs/MIDS271_Lab1/Lab_1/report")
cereal <- read_csv('/home/rstudio/workspace/mnt/271/labs/MIDS271_Lab1/Lab_1/data/short-questions/cereal_dillons.csv')
```


## Recode Data 
(1 point) The explanatory variables need to be reformatted before proceeding further (sample code is provided in the textbook). First, divide each explanatory variable by its serving size to account for the different serving sizes among the cereals. Second, rescale each variable to be within 0 and 1. Construct side-by-side box plots with dot plots overlaid for each of the explanatory variables. Also, construct a parallel coordinates plot for the explanatory variables and the shelf number. Discuss whether possible content differences exist among the shelves.

```{r recode data}
# rescale the values between 0 and 1
Rescale <- function(values) {
    return((values - min(values)) / (max(values) - min(values)))
}

cereal <- cereal %>%
    mutate(
        Shelf = factor(Shelf),
        Cereal = factor(Cereal),
        sodium_g = (sodium_mg / 1000),
        sugar = Rescale(sugar_g / size_g),
        fat = Rescale(fat_g / size_g),
        sodium = Rescale(sodium_g / size_g)
    )
```

```{r boxplots, fig.align="center", echo=F, fig.align="center", warning=F, results='hide'}
BoxPlot <- function(df, col) {
    return(
        df %>% ggplot(aes(x = Shelf, y = !!sym(col))) +
            geom_boxplot(aes(fill = Shelf)) +
            geom_dotplot(binaxis = "y", stackdir = "center", binwidth = 0.05) +
            labs(fill = "Shelf") +
            coord_flip() +
            ggtitle(col) +
            theme(plot.title = element_text(lineheight = 1, face = "bold")) +
            ylab(col) +
            xlab("Shelf")
    )
}

BoxPlot(cereal, "sugar") | BoxPlot(cereal, "fat") | BoxPlot(cereal, "sodium")
```

> Shelf 2 has the highest probability for sugar and shelf 1 has the highest probability for sodium. fat doesnt seem to have any particular self that has a high probability. 

```{r parallel coordiantes plot, echo=F, fig.align="center", fig.height=3, warning=F, results='hide'}
cereal %>% select(Shelf, sugar, fat, sodium) %>% ggparcoord(
    columns = 2:4,
    groupColumn = 1,
    showPoints = TRUE,
    scale = "globalminmax",
    title = "Parallel Coordinates Plot for Explanatory Variables and Shelf Number",
    alphaLines = 0.5
)
```

> shelf 2 has a lot of negative values for size_g and a positive values for sugar. The opposite is for shelf 3, it has a positive value for size_g and negative values for sugar.

> There is some content differences between the shelves. Size, sugar and fat are good examples where we can see the dispersion of the different shelves in each.

## Evaluate Ordinal vs. Categorical 
(1 point) The response has values of $1, 2, 3,$ and $4$. Explain under what setting would it be desirable to take into account ordinality, and whether you think that this setting occurs here. Then estimate a suitable multinomial regression model with linear forms of the sugar, fat, and sodium variables. Perform LRTs to examine the importance of each explanatory variable. Show that there are no significant interactions among the explanatory variables (including an interaction among all three variables).

> settings that take into account ordinality are things like grades or a Likert scale. In this case, because the shelves do not need to be in order or a series they can be considered nomial.

```{r multinomial logit regressions, results=F}
model_cereal_shelves_linear <- multinom(Shelf ~ sugar + fat + sodium, data = cereal)
summary(model_cereal_shelves_linear)

model_cereal_shelves_quadratic <- multinom(
    Shelf ~ sugar + fat + sodium +
    sugar:fat + sugar:sodium + fat:sodium + sugar:fat:sodium,
    data = cereal
)
summary(model_cereal_shelves_quadratic)
```

```{r likelihood ratio tests: main effects}
lrt_cereal_main_effects <- round(Anova(model_cereal_shelves_linear), 4)
lrt_cereal_main_effects
```

```{r likelihood ratio tests: interaction effects} 
lrt_cereal_quadratic_effects <- round(Anova(model_cereal_shelves_quadratic), 4)
lrt_cereal_quadratic_effects
```

> looking at the p-values for the main effect model $sugar = `r lrt_cereal_main_effects[1,3]`$ and $sodium = `r lrt_cereal_main_effects[3,3]`$ making them very statistically significant. $fat = `r lrt_cereal_main_effects[2,3]`$ making it $> 0.1$ which means it is not statistically significant.
>
> Looking at the the p-values for the quadratic effect model $sugar = `r lrt_cereal_quadratic_effects[1,3]`$ and $sodium = `r lrt_cereal_quadratic_effects[3,3]`$ making them both still very statistically significant. $fat = `r lrt_cereal_quadratic_effects[2,3]`$ is still $> 0.1$ making it not statistically significant. for the interactions we have $sugar:fat = `r lrt_cereal_quadratic_effects[4,3]`$, $sugar:sodium = `r lrt_cereal_quadratic_effects[5,3]`$, $fat:sodium = `r lrt_cereal_quadratic_effects[6,3]`$, and $sugar:fat:sodium = `r lrt_cereal_quadratic_effects[7,3]`$ this means that all the interactions have are $> 0.1$ making them all not statistically significant which means we can omit them from the model.

## Where do you think Apple Jacks will be placed? 
(1 point) Kellogg's Apple Jacks (http://www.applejacks.com) is a cereal marketed toward children. For a serving size of $28$ grams, its sugar content is $12$ grams, fat content is $0.5$ grams, and sodium content is $130$ milligrams. Estimate the shelf probabilities for Apple Jacks.

```{r predictions for apple jacks}
Rescale2 <- function(value, col) {
    minn <- ifelse(value < min(cereal[col] / cereal$size_g), value, min(cereal[col] / cereal$size_g))
    maxx <- ifelse(value > max(cereal[col] / cereal$size_g), value, max(cereal[col] / cereal$size_g))
    return((value - minn) / (maxx - minn))
}
apple_jacks <- data.frame(
    sugar = Rescale2(12 / 28, "sugar_g"),
    fat = Rescale2(0.5 / 28, "fat_g"),
    sodium = Rescale2((130 / 1000) / 28, "sodium_g")
)
aj_shelf_probs <- predict(model_cereal_shelves_linear, newdata = apple_jacks, type = "probs")
round(aj_shelf_probs, 4)
```

> Our model predicts that the apple jacks will be placed on shelf `r which.max(aj_shelf_probs)` with a $`r round(max(aj_shelf_probs) * 100, 2)`\%$.

## Figure 3.3 
(1 point) Construct a plot similar to Figure 3.3 where the estimated probability for a shelf is on the *y-axis* and the sugar content is on the *x-axis*. Use the mean overall fat and sodium content as the corresponding variable values in the model. Interpret the plot with respect to sugar content.

```{r create figure 3.3, echo=F, fig.align="center", warning=F, results='hide'}
# Define a function to calculate predicted probabilities for each shelf using mean fat and sugar
predict_prob <- function(sugar, model) {
  graph_data <- data.frame(sugar = sugar,
                         fat = mean(cereal$fat),
                         sodium = mean(cereal$sodium))
  predicted_probs <- predict(model, newdata = graph_data, type = "probs")
  return(predicted_probs)
}

# Plot the predicted probabilities for each shelf
# Plot Shelf 1
curve(predict_prob(x, model_cereal_shelves_linear)[, "1"], from = 0, to = 1,
      xlab = "Sugar", ylab = expression(hat(pi)), 
      main = "Predicted Probability of Shelf for Varying Sugar",
      col = "blue", lwd = 2, ylim = c(0, 1))

# Plot Shelf 2
curve(predict_prob(x, model_cereal_shelves_linear)[, "2"], add = TRUE,
      col = "red", lwd = 2)

# Plot Shelf 3
curve(predict_prob(x, model_cereal_shelves_linear)[, "3"], add = TRUE,
      col = "green", lwd = 2)

# Plot Shelf 4
curve(predict_prob(x, model_cereal_shelves_linear)[, "4"], add = TRUE,
      col = "purple", lwd = 2)

# Create a legend
legend("topleft", legend = c("Shelf 1", "Shelf 2", "Shelf 3", "Shelf 4"),
       col = c("blue", "red", "green", "purple"), lwd = 2)
```

> The plot is telling me that shelf 2 has a very high probability with high sugar and the rest of the shelve has very low to no probability with high sugar. shelf 3 and 4 have high probabilities when the sugar is low or none. All the shelves have roughly almost the same probability when the sugar is around 0.6 and 0.7.

## Odds ratios 
(1 point) Estimate odds ratios and calculate corresponding confidence intervals for each explanatory variable. Relate your interpretations back to the plots constructed for this exercise. 

```{r produce odds ratios}
odds_ratios <- round(exp(coef(model_cereal_shelves_linear)[,2:4]),2)
odds_ratios

cis_odd_ratios <- exp(confint(model_cereal_shelves_linear, level = 0.95))
cis_odd_ratios[2:4,,]
```

> The estimated odds of Shelf 2 versus 1 change by `r odds_ratios[1,1]` times for `sugar` holding the other variables constant. Also, The estimated odds of Shelf 2 versus 1 change by `r odds_ratios[1,2]` times for `fat` holding the other varaibles constant. The estimated odds of Shelf 3 versus 1 change by `r odds_ratios[2,2]` times for `fat` holding the other variables constant. The estimated odds of Shelf 3 versus 1 change by `r odds_ratios[3,2]` times for `fat` holding the other variables constant. the odds for `sodium` have a very low effect on all shelves against the first shelf holding other variabels constant.


# Alcohol, self-esteem and negative relationship interactions (5 points)

Read the example **'Alcohol Consumption'** in chapter 4.2.2 of the textbook(Bilder and Loughin’s “Analysis of Categorical Data with R). This is based on a study in which moderate-to-heavy drinkers (defined as at least 12 alcoholic drinks/week for women, 15 for men) were recruited to keep a daily record of each drink that they consumed over a 30-day study period. Participants also completed a variety of rating scales covering daily events in their lives and items related to self-esteem. The data are given in the *DeHartSimplified.csv *data set. Questions 24-26 of chapter 3 of the textbook also relate to this data set and give definitions of its variables: the number of drinks consumed (`numall`), positive romantic-relationship events (`prel`), negative romantic-relationship events (`nrel`), age (`age`), trait (long-term) self-esteem (`rosn`), state (short-term) self-esteem (`state`).

The researchers stated the following hypothesis:

> *We hypothesized that negative interactions with romantic partners would be associated with alcohol consumption (and an increased desire to drink). We predicted that people with low trait self-esteem would drink more on days they experienced more negative relationship interactions compared with days during which they experienced fewer negative relationship interactions. The relation between drinking and negative relationship interactions should not be evident for individuals with high trait self-esteem.*

```{r read drinking data, include=FALSE}
drinks <- read_csv('/home/rstudio/workspace/mnt/271/labs/MIDS271_Lab1/Lab_1/data/short-questions/DeHartSimplified.csv')
```

## EDA 
(2 points) Conduct a thorough EDA of the data set, giving special attention to the relationships relevant to the researchers' hypotheses. Address the reasons for limiting the study to observations from only one day.

```{r drinking EDA, warning=F, message=F}
# Median and above is defined as "high self esteem" for both rosn and state
drinks <- drinks %>%
  mutate(trait_bin = cut(rosn, breaks = 3), state_bin = cut(state, breaks=3))

agg_df <- aggregate(drinks$numall, by=list(drinks$id), FUN=mean) %>%
  rename("avg_drinks" = "x", "id" = "Group.1")

drinks <- inner_join(x=drinks, y=agg_df, by="id") 

drinks <- mutate(drinks, scaled_drinks = numall / avg_drinks)

pairs(~numall + scaled_drinks + nrel + prel + rosn +state, data = drinks)
```
```{r additional eda, echo=F, fig.align="center", warning=F, results='hide'}
p_0 <- drinks %>%
  ggplot(aes(x= numall, y = ..prop.., group = 1)) +
  geom_bar(fill = 'DarkBlue', color = 'black') +
  geom_text(stat='count', aes(label=..count..), vjust=-1) +
  xlab("Number of Drinks") +
  ylab("Proportion") +
  ylim(0,0.35)
p_0

p1 <- drinks %>%
  ggplot(aes(y = nrel, x = numall)) +
  geom_point()

p2 <- drinks %>%
  ggplot(aes(y = nrel, x = numall)) +
  geom_point()

p4 <- drinks %>%
  ggplot(aes(y = nrel, x = scaled_drinks)) +
  geom_point()

p5 <- drinks %>%
  ggplot(aes(x = nrel)) +
  geom_density(aes(y = ..density.., color = trait_bin, fill = trait_bin),alpha=0.2)

p6 <- drinks %>%
  ggplot(aes(x = nrel)) +
  geom_density(aes(y = ..density.., color = state_bin, fill = state_bin),alpha=0.2)

p7 <- drinks %>%
  ggplot(aes(x = numall)) +
  geom_density(aes(y = ..density.., color = trait_bin, fill = trait_bin),alpha=0.2)

p8 <- drinks %>%
  ggplot(aes(x = numall)) +
  geom_density(aes(y = ..density.., color = state_bin, fill = state_bin),alpha=0.2)

grid.arrange(p1, p2, p4, nrow = 3, ncol = 1)
grid.arrange(p5, p6, p7, p8, nrow = 4, ncol = 1)
```

On the surface, we don't observe strong linear relationships between the number of drinks and the number of negative relationship events. We do see some evidence that folks with lower 'state' and 'trait' self esteem values. tend to consume more drinks, but it is not compelling evidence on its own. 

## Hypothesis One 
(2 points) The researchers hypothesize that negative interactions with romantic partners would be associated with alcohol consumption and an increased desire to drink. Using appropriate models, evaluate the evidence that negative relationship interactions are associated with higher alcohol consumption and an increased desire to drink. 

```{r poisson modeling, results=F}
poisson_mod <- glm(numall ~ nrel, data = drinks, family = poisson(link="log"))
summary(poisson_mod)

(exp(coef(poisson_mod)))
```
We find a statistically significant positive correlation between negative relationship events and the number of drinks consumed. Exponentiating our coefficient, we can see that each 1-unit increase in negative relationship events corresponds to a 6.7% increase in average drinks consumed.

We've limited the study to drinks on a single day, in order to keep the observation period consistent to fit the assumption of the Poisson distribution.

## Hypothesis Two
(1 point) The researchers hypothesize that the relation between drinking and negative relationship interactions should not be evident for individuals with high trait self-esteem. Conduct an analysis to address this hypothesis.

```{r poisson modeling 2, results=F}
poisson_mod <- glm(numall ~ nrel + trait_bin, data = drinks, family = poisson(link="log"))
summary(poisson_mod)

(exp(coef(poisson_mod))-1)*100
```

We divided the participants into 3 bins based on their trait self esteem, and see that, despite being in the highest bin, the negative relationship events continue to have a statistically significant effect on the number of drinks consumed. The effect is muted, but not absent, in individuals with high self esteem.
